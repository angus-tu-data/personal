{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5518df56",
   "metadata": {},
   "source": [
    "Data Engineer OnBoard - Week 2 \n",
    "# GCS and BigQuery\n",
    "Angus Tu\n",
    "2025.09.17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ba0aed",
   "metadata": {},
   "source": [
    "----\n",
    "# BigQuery\n",
    "BigQuery can be accessed and operated via the `BQ CLI command line`, `BQ SQL syntax`, or `Python` (e.g., using `pandas`) etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbbcc65",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "\n",
    "## Set Permission \n",
    "You need the <u>BigQuery Job User</u> and <u>BigQuery Data Editor</u> role and the permissions <u>storage.buckets.create</u> and <u>storage.buckets.list</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7bd74",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "gcloud config configurations activate default\n",
    "gcloud projects add-iam-policy-binding tw-rd-data-angus-tu \\\n",
    "    --member=\"serviceAccount:angus-personal@tw-rd-data-angus-tu.iam.gserviceaccount.com\" \\\n",
    "    --role=\"roles/bigquery.jobUser\"\n",
    "gcloud projects add-iam-policy-binding tw-rd-data-angus-tu \\\n",
    "    --member=\"serviceAccount:angus-personal@tw-rd-data-angus-tu.iam.gserviceaccount.com\" \\\n",
    "    --role=\"roles/bigquery.dataEditor\" \n",
    "gcloud projects add-iam-policy-binding tw-rd-data-angus-tu \\\n",
    "    --member=\"serviceAccount:angus-personal@tw-rd-data-angus-tu.iam.gserviceaccount.com\" \\\n",
    "    --role=\"roles/bigquery.user\" \n",
    "gcloud config configurations activate sa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011ecfb",
   "metadata": {},
   "source": [
    "## Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36eb723",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE SCHEMA IF NOT EXISTS `tw-rd-data-angus-tu.travel_demo`\n",
    "OPTIONS(location=\"asia-east1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc99596",
   "metadata": {},
   "source": [
    "## Create a (Partition/Clustering) Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce929a",
   "metadata": {},
   "source": [
    "### 1. Create an empty table, and import a DataFrame from Python pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b2b48",
   "metadata": {},
   "source": [
    "> Create an empty partition and clustering table via BQ SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810c4e5",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE IF NOT EXISTS `travel_demo.order` (\n",
    "  MID string,\n",
    "  PID string,\n",
    "  date date\n",
    ")\n",
    "PARTITION BY date\n",
    "CLUSTER BY MID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a34d89",
   "metadata": {},
   "source": [
    "> [Sample Data] ORDER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bebd8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---------------------+\n",
      "| MID       | PID   | date                |\n",
      "+===========+=======+=====================+\n",
      "| M33430978 | P498  | 2025-02-22 00:00:00 |\n",
      "+-----------+-------+---------------------+\n",
      "| M36302512 | P277  | 2024-12-11 00:00:00 |\n",
      "+-----------+-------+---------------------+\n",
      "| M27964407 | P403  | 2023-10-01 00:00:00 |\n",
      "+-----------+-------+---------------------+\n",
      "| M69658690 | P486  | 2024-10-30 00:00:00 |\n",
      "+-----------+-------+---------------------+\n",
      "| M50233372 | P324  | 2025-07-17 00:00:00 |\n",
      "+-----------+-------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from tabulate import tabulate\n",
    "\n",
    "def funcOrder(n):\n",
    "    mids = np.char.add(\"M\", np.random.randint(10000000, 100000000, size=n).astype(str))\n",
    "    pids = np.char.add(\"P\",np.random.randint(100, 1000, size=n).astype(str))\n",
    "    start_date = np.datetime64('2023-01-01')\n",
    "    end_date = np.datetime64('today')\n",
    "    delta_days = (end_date - start_date).astype(int)\n",
    "    random_days = np.random.randint(0, delta_days + 1, size=n)\n",
    "    dates = start_date + random_days.astype('timedelta64[D]')\n",
    "    df = pd.DataFrame({'MID': mids,'PID': pids,'date': dates})\n",
    "    return df\n",
    "\n",
    "order_df = funcOrder(100000)\n",
    "print(tabulate(order_df.head(5), headers='keys', tablefmt='grid', showindex=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a011af49",
   "metadata": {},
   "source": [
    "> Import data from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aec3ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=tw-rd-data-angus-tu, location=asia-east1, id=bfb1aa8b-ab13-4508-a95f-9cdab00b51f3>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "BQ = bigquery.Client()\n",
    "table_ref = \"travel_demo.order\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\",\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"MID\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"PID\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"date\", \"DATE\"),\n",
    "    ])\n",
    "job = BQ.load_table_from_dataframe(order_df, table_ref, job_config=job_config)\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a78c6",
   "metadata": {},
   "source": [
    "### 2. Import a CSV via GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0304739a",
   "metadata": {},
   "source": [
    "> [Sample Data] PROD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d127d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "| PID   |   amount |\n",
      "+=======+==========+\n",
      "| P100  |    70500 |\n",
      "+-------+----------+\n",
      "| P101  |    60200 |\n",
      "+-------+----------+\n",
      "| P102  |    35400 |\n",
      "+-------+----------+\n",
      "| P103  |    92400 |\n",
      "+-------+----------+\n",
      "| P104  |    57500 |\n",
      "+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "pids = [f\"P{i}\" for i in range(100, 1000)]  # P100 ~ P999\n",
    "n = len(pids)\n",
    "amounts = np.random.randint(1, 1000, size=n) * 100\n",
    "prod_df = pd.DataFrame({\"PID\": pids, \"amount\": amounts})\n",
    "\n",
    "prod_df.to_csv(\"travel_demo_prod.csv\", index=False)\n",
    "print(tabulate(prod_df.head(5), headers='keys', tablefmt='grid', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a0357",
   "metadata": {},
   "source": [
    "> Upload file to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e918ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(client, bucket_name, source_file_name, sink_file_name, sink_dir = \"\"):\n",
    "\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    if sink_dir: \n",
    "        sink_dir = sink_dir.rstrip(\"/\") + \"/\"\n",
    "    blob_name = sink_dir + sink_file_name\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    return f\"gs://{bucket_name}/{blob_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1184c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://tw-rd-data-angus-tu-travel-demo1/test/prod.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "GCS = storage.Client()\n",
    "upload_file(GCS, \"tw-rd-data-angus-tu-travel-demo1\", \"travel_demo_prod.csv\", \"prod.csv\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3c3a8",
   "metadata": {},
   "source": [
    "> Load via BQ SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d85f97",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "LOAD DATA OVERWRITE `travel_demo.prod` (PID STRING, amount INT64)\n",
    "FROM FILES (\n",
    "  format = 'CSV',\n",
    "  uris = ['gs://tw-rd-data-angus-tu-travel-demo1/test/prod.csv'],\n",
    "  skip_leading_rows = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de95b5",
   "metadata": {},
   "source": [
    "> Load via Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "829099b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=tw-rd-data-angus-tu, location=asia-east1, id=fbf936d8-e63a-4443-8dff-a0ce0608d333>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"PID\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"ammount\", \"INT64\"),\n",
    "    ],\n",
    "    skip_leading_rows=1,\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "uri = 'gs://tw-rd-data-angus-tu-travel-demo1/test/prod.csv'\n",
    "\n",
    "job = BQ.load_table_from_uri(uri, \"travel_demo.prod2\", job_config=job_config)\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8b39d",
   "metadata": {},
   "source": [
    "## Create a View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b761cc2",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE VIEW `travel_demo.order_in_7_days`\n",
    "AS\n",
    "select MID, PID, date\n",
    "from `travel_demo.order`\n",
    "where date >= current_date()-7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0ebde10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------------+\n",
      "| MID       | PID   | date       |\n",
      "+===========+=======+============+\n",
      "| M22375521 | P112  | 2025-09-16 |\n",
      "+-----------+-------+------------+\n",
      "| M61134922 | P114  | 2025-09-16 |\n",
      "+-----------+-------+------------+\n",
      "| M28510495 | P117  | 2025-09-16 |\n",
      "+-----------+-------+------------+\n",
      "| M39955645 | P118  | 2025-09-16 |\n",
      "+-----------+-------+------------+\n",
      "| M19579881 | P130  | 2025-09-16 |\n",
      "+-----------+-------+------------+\n"
     ]
    }
   ],
   "source": [
    "view_df = BQ.query(\"select * from `travel_demo.order_in_7_days` limit 1000\").to_dataframe()\n",
    "print(tabulate(view_df.head(5), headers='keys', tablefmt='grid', showindex=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
